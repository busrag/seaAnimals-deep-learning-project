{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5198507,"sourceType":"datasetVersion","datasetId":2442436},{"sourceId":13146645,"sourceType":"datasetVersion","datasetId":8329303},{"sourceId":13147316,"sourceType":"datasetVersion","datasetId":8329788},{"sourceId":13148674,"sourceType":"datasetVersion","datasetId":8330670},{"sourceId":13906679,"sourceType":"datasetVersion","datasetId":8328073}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"✿ Orijinal veri setindeki sınıfları görüntülüyorum.","metadata":{}},{"cell_type":"code","source":"import os\n\nbase_dir = \"/kaggle/input/sea-animals-image-dataste\"\nprint(os.listdir(base_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:43:26.817516Z","iopub.execute_input":"2025-09-26T05:43:26.817764Z","iopub.status.idle":"2025-09-26T05:43:26.838422Z","shell.execute_reply.started":"2025-09-26T05:43:26.817747Z","shell.execute_reply":"2025-09-26T05:43:26.837237Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Her sınıfa ait ne kadar görsel olduğuna da baktım.","metadata":{}},{"cell_type":"code","source":"for c in os.listdir(base_dir):\n    c_path = os.path.join(base_dir, c)\n    print(f\"{c}: {len(os.listdir(c_path))} adet görsel\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:43:28.857306Z","iopub.execute_input":"2025-09-26T05:43:28.857585Z","iopub.status.idle":"2025-09-26T05:43:29.312082Z","shell.execute_reply.started":"2025-09-26T05:43:28.857564Z","shell.execute_reply":"2025-09-26T05:43:29.311306Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Aynı işlemleri iki farklı sınıf içeren kendi veri setim için de yaptım.","metadata":{}},{"cell_type":"code","source":"import os\n\nbase_dir = \"/kaggle/input/instructor-sea-animals-photos-dataset\"\nprint(os.listdir(base_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T10:06:52.757430Z","iopub.execute_input":"2025-11-28T10:06:52.758609Z","iopub.status.idle":"2025-11-28T10:06:52.769455Z","shell.execute_reply.started":"2025-11-28T10:06:52.758573Z","shell.execute_reply":"2025-11-28T10:06:52.768354Z"}},"outputs":[{"name":"stdout","text":"['instructor-sea-animals-photos-dataset']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"for c in os.listdir(base_dir):\n    c_path = os.path.join(base_dir, c)\n    print(f\"{c}: {len(os.listdir(c_path))} adet görsel\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:43:33.785194Z","iopub.execute_input":"2025-09-26T05:43:33.785657Z","iopub.status.idle":"2025-09-26T05:43:33.812270Z","shell.execute_reply.started":"2025-09-26T05:43:33.785635Z","shell.execute_reply":"2025-09-26T05:43:33.810310Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Veri Setlerini Birleştirme\n\n✿  Orijinal veri setini working alanında oluşturduğum 'merged_dataset' klasörüne kopyalıyorum.","metadata":{}},{"cell_type":"code","source":"import shutil\nimport os\n\n\nsrc = \"/kaggle/input/sea-animals-image-dataste\"\n\ndst = \"/kaggle/working/merged_dataset\"\n\nos.makedirs(dst, exist_ok=True)\nshutil.copytree(src, dst, dirs_exist_ok=True)\n\nprint(\"Orijinal dataset merged_dataset içine kopyalandı.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:54:39.440107Z","iopub.execute_input":"2025-09-26T05:54:39.440677Z","iopub.status.idle":"2025-09-26T05:57:31.123517Z","shell.execute_reply.started":"2025-09-26T05:54:39.440653Z","shell.execute_reply":"2025-09-26T05:57:31.122848Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Kendi veri setimde bulunan `InstructorCorals` sınıfındaki tüm görselleri `merged_dataset` içerisindeki `Corals` sınıfına kopyalıyorum.","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\nsrc = \"/kaggle/input/instructor-sea-animals-photos-dataset/InstructorCorals\"\ndst = \"/kaggle/working/merged_dataset/Corals\"\n\nos.makedirs(dst, exist_ok=True)\n\nfor img in os.listdir(src):\n    src_path = os.path.join(src, img)\n    dst_path = os.path.join(dst, img)\n    shutil.copy(src_path, dst_path)\n\nprint(\"InstructorCorals görselleri merged_dataset/Corals içine kopyalandı.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:57:46.093318Z","iopub.execute_input":"2025-09-26T05:57:46.093930Z","iopub.status.idle":"2025-09-26T05:57:46.292063Z","shell.execute_reply.started":"2025-09-26T05:57:46.093908Z","shell.execute_reply":"2025-09-26T05:57:46.291113Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Aynı işlemi `InstructorFish` sınıfındaki görseller için de yapıyorum. Bu kez görseller `merged_dataset`'te bulunan `Fish` sınıfına kopyalanıyor.","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\n\nsrc_fish   = \"/kaggle/input/instructor-sea-animals-photos-dataset/InstructorFish\"\ndst_fish   = \"/kaggle/working/merged_dataset/Fish\"\n\nos.makedirs(dst_fish, exist_ok=True)\n\nfor img in os.listdir(src_fish):\n    shutil.copy(os.path.join(src_fish, img), os.path.join(dst_fish, img))\n\nprint(\"InstructorFish görselleri merged_dataset/Fish içine kopyalandı.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:57:48.538925Z","iopub.execute_input":"2025-09-26T05:57:48.539517Z","iopub.status.idle":"2025-09-26T05:57:48.891412Z","shell.execute_reply.started":"2025-09-26T05:57:48.539491Z","shell.execute_reply":"2025-09-26T05:57:48.890608Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ working içinde bulunan `merged_dataset`'i kalıcı bir dataset haline getirebilmek için zip dosyası haline getirip kendi bilgisayarıma yükledikten sonra input alanına `my-merged-dataset` adı ile upload ediyorum. Böylece kendi veri setim ile orijinal veri setini birleştirdiğim bir veri seti oluşturmuş oluyorum.","metadata":{}},{"cell_type":"code","source":"import shutil\n\nfolder_to_zip = \"/kaggle/working/merged_dataset\"\n\noutput_zip = \"/kaggle/working/merged_dataset.zip\"\n\nshutil.make_archive(\"/kaggle/working/merged_dataset\", 'zip', folder_to_zip)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T17:02:49.209109Z","iopub.execute_input":"2025-09-25T17:02:49.209399Z","iopub.status.idle":"2025-09-25T17:02:59.618508Z","shell.execute_reply.started":"2025-09-25T17:02:49.209378Z","shell.execute_reply":"2025-09-25T17:02:59.617927Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Görselleri Temizleme ve Standart Formata Dönüştürme\n\n✿ Bu hücrede, `my-merged-dataset` klasöründeki tüm görseller:\n\n- **RGB renk formatına** dönüştürülüyor,  \n- **224x224 boyutuna** yeniden boyutlandırılıyor,  \n- **JPEG formatında** ve yüksek kalite (quality=95) ile `cleaned_dataset` klasörüne kaydediliyor.\n   \n✿ Her sınıf için ayrı klasörler oluşturuluyor ve dosya isimleri korunuyor.  \n✿ Hatalı veya açılamayan görselleri ekrana yazdırarak da işlem sırasında gözlemleyebiliyorum.  \n","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\n\n\ninput_dir = \"/kaggle/input/my-merged-dataset\"\noutput_dir = \"/kaggle/working/cleaned_dataset\"\n\nos.makedirs(output_dir, exist_ok=True)\n\nfor class_name in os.listdir(input_dir):\n    class_path = os.path.join(input_dir, class_name)\n    if not os.path.isdir(class_path):\n        continue\n\n    output_class_path = os.path.join(output_dir, class_name)\n    os.makedirs(output_class_path, exist_ok=True)\n\n    for img_name in os.listdir(class_path):\n        try:\n            img_path = os.path.join(class_path, img_name)\n            img = Image.open(img_path).convert(\"RGB\")\n            img = img.resize((224, 224))       \n            new_name = os.path.splitext(img_name)[0] + \".jpg\"\n            save_path = os.path.join(output_class_path, new_name)\n            img.save(save_path, \"JPEG\", quality=95)\n        except Exception as e:\n            print(f\"Hata: {img_name}, {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T05:57:56.122211Z","iopub.execute_input":"2025-09-26T05:57:56.122929Z","iopub.status.idle":"2025-09-26T06:01:21.872555Z","shell.execute_reply.started":"2025-09-26T05:57:56.122905Z","shell.execute_reply":"2025-09-26T06:01:21.871943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Temizlenmiş veri setimi kaybetmemek için tekrar zip dosyası haline getirip kendi bilgisayarıma indirdikten sonra input dataset alanına `cleaned-dataset`adı ile upload ediyorum.","metadata":{}},{"cell_type":"code","source":"import shutil\n\nfolder_to_zip = \"/kaggle/working/cleaned_dataset\"\noutput_zip = \"/kaggle/working/cleaned_dataset.zip\"\n\nshutil.make_archive(\"/kaggle/working/cleaned_dataset\", 'zip', folder_to_zip)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:02:29.500941Z","iopub.execute_input":"2025-09-26T06:02:29.501529Z","iopub.status.idle":"2025-09-26T06:02:39.153998Z","shell.execute_reply.started":"2025-09-26T06:02:29.501508Z","shell.execute_reply":"2025-09-26T06:02:39.153352Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset'i Train/Validation/Test Olarak Bölme\n\n✿ Bu hücrede`cleaned_dataset` klasöründeki verileri **train**, **val** ve **test** setleri olarak ayırıyorum. Ardında ayrılmış dataseti working alanına dataset_split olarak kaydediyorum.\n\n   `train_ratio = 0.7` -> Verilerin %70'i eğitim için.  \n   `val_ratio = 0.15` -> Verilerin %15'i doğrulama için.  \n   `test_ratio = 0.15` -> Verilerin %15'i test için.  \n\n✿ Her sınıf için resimler rastgele karıştırılıyor ve ilgili klasörlere kopyalanıyor.  \n  \n✿ Sonuç olarak model eğitiminde ve değerlendirmesinde kullanılacak verileri düzenli bir şekilde ayırmış oluyorum.","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\nsource_dir = \"/kaggle/working/cleaned_dataset\"\n\nsplit_dir = \"/kaggle/working/dataset_split\"\nos.makedirs(split_dir, exist_ok=True)\n\ntrain_ratio = 0.7\nval_ratio = 0.15\ntest_ratio = 0.15\n\nfor class_name in os.listdir(source_dir):\n    class_path = os.path.join(source_dir, class_name)\n    if not os.path.isdir(class_path):\n        continue\n\n    imgs = [f for f in os.listdir(class_path) if f.lower().endswith(\".jpg\")]\n    random.shuffle(imgs)\n\n    n_total = len(imgs)\n    n_train = int(n_total * train_ratio)\n    n_val = int(n_total * val_ratio)\n    n_test = n_total - n_train - n_val\n\n    splits = {\n        \"train\": imgs[:n_train],\n        \"val\": imgs[n_train:n_train+n_val],\n        \"test\": imgs[n_train+n_val:]\n    }\n\n    for split_name, split_imgs in splits.items():\n        split_class_dir = os.path.join(split_dir, split_name, class_name)\n        os.makedirs(split_class_dir, exist_ok=True)\n        for img_name in split_imgs:\n            src_path = os.path.join(class_path, img_name)\n            dst_path = os.path.join(split_class_dir, img_name)\n            shutil.copy(src_path, dst_path)\n\nprint(\"Dataset train/val/test olarak ayrıldı ve dataset_split klasörüne kaydedildi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:02:59.196859Z","iopub.execute_input":"2025-09-26T06:02:59.197117Z","iopub.status.idle":"2025-09-26T06:03:00.922849Z","shell.execute_reply.started":"2025-09-26T06:02:59.197099Z","shell.execute_reply":"2025-09-26T06:03:00.922170Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Kalıcılık adına bu klasörü de zip dosyası haline getirip kendi bilgisayarıma indirdikten sonra input dataset alanına `split-dataset` adı ile upload ediyorum.","metadata":{}},{"cell_type":"code","source":"import shutil\n\nfolder_to_zip = \"/kaggle/working/dataset_split\"\noutput_zip = \"/kaggle/working/dataset_split.zip\"\n\nshutil.make_archive(\"/kaggle/working/dataset_split\", 'zip', folder_to_zip)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T14:00:04.434143Z","iopub.execute_input":"2025-09-23T14:00:04.435234Z","iopub.status.idle":"2025-09-23T14:00:15.694608Z","shell.execute_reply.started":"2025-09-23T14:00:04.435198Z","shell.execute_reply":"2025-09-23T14:00:15.693776Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train Seti Sınıf Dağılımının Görselleştirilmesi\n\n✿ Data augmentation öncesi `dataset_split/train` klasöründeki her sınıfın görsel sayısını hesaplıyor ve grafik ile görselleştiriyorum.  \n  \n- `plt.xticks(rotation=90)` komutuyla sınıf isimlerini dikey göstererek okunabilirliği arttırıyorum.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\n\nsplit_dir = \"/kaggle/working/dataset_split/train\"\n\nclass_counts = {}\nfor class_name in os.listdir(split_dir):\n    class_path = os.path.join(split_dir, class_name)\n    count = len([f for f in os.listdir(class_path) if f.lower().endswith(\".jpg\")])\n    class_counts[class_name] = count\n\nplt.figure(figsize=(12,6))\nplt.bar(class_counts.keys(), class_counts.values(), color='teal')\nplt.xticks(rotation=90)\nplt.ylabel(\"Görsel Sayısı\")\nplt.title(\"Train Seti Sınıf Dağılımı\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:03:06.444200Z","iopub.execute_input":"2025-09-26T06:03:06.445078Z","iopub.status.idle":"2025-09-26T06:03:06.909275Z","shell.execute_reply.started":"2025-09-26T06:03:06.445051Z","shell.execute_reply":"2025-09-26T06:03:06.908460Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ImageDataGenerator ile Veri Ön İşleme ve Augmentation\n\n✿ Bu hücrede `ImageDataGenerator` kullanarak train, validation ve test verilerini hazırlıyorum.  \n\n* **Train seti** için uyguladığım **data augmentation** teknikleri:\n\n    Normalizasyon (`rescale=1./255`)\n    Döndürme (0–30°)  \n    Yatay/dikey kaydırma (%10)  \n    Zoom (%20)  \n    Yatay çevirme  \n    Parlaklık jitter  \n    `fill_mode=\"nearest\"` ile boşluk doldurma\n\n✿ **Validation** ve **Test** setlerinde yalnızca **normalize** işlemi yapıyorum.  \n\n✿ Sonrasında `flow_from_directory` metodu ile train, validation ve test klasörlerinden veri okuyarak `generator` objeleri oluşturuyorum. Bu sayede model eğitiminde mini-batch halinde veriler otomatik besleniyor.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,          \n    rotation_range=30,       \n    width_shift_range=0.1,   \n    height_shift_range=0.1,  \n    zoom_range=0.2,         \n    horizontal_flip=True,    \n    vertical_flip=False,     \n    brightness_range=[0.8,1.2], \n    fill_mode=\"nearest\"\n)\n\n# Validation ve test için sadece normalize \nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_dir = \"/kaggle/working/dataset_split/train\"\nval_dir   = \"/kaggle/working/dataset_split/val\"\ntest_dir  = \"/kaggle/working/dataset_split/test\"\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224,224),\n    batch_size=32,\n    class_mode=\"categorical\"\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(224,224),\n    batch_size=32,\n    class_mode=\"categorical\"\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(224,224),\n    batch_size=64,\n    class_mode=\"categorical\",\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:03:13.076729Z","iopub.execute_input":"2025-09-26T06:03:13.077207Z","iopub.status.idle":"2025-09-26T06:03:13.396891Z","shell.execute_reply.started":"2025-09-26T06:03:13.077183Z","shell.execute_reply":"2025-09-26T06:03:13.396162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Augmentation Sonuçlarını Görselleştirme\n\n✿ Bu hücrede, `ImageDataGenerator` ile tanımlanan **data augmentation** işlemlerinin görsellere nasıl yansıdığı inceleyebilmek için görselleştirme yapıyorum.  \n\n- Eğitim setinden bir batch alıp (32 görsel), ilk 9 görsel 3x3 grid halinde çizdiriliyor.  \n\n✿ Bu sayede döndürme, kaydırma, zoom, yatay çevirme ve parlaklık değişikliklerinin örnek görseller üzerinde nasıl çalıştığını gözlemleyebiliyorum.  \n✿ Modelin daha genelleştirilebilir hale gelmesi için augmentation etkileri burada görsel olarak kontrol edilmiş oluyor.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,      \n    width_shift_range=0.1,   \n    height_shift_range=0.1, \n    zoom_range=0.2,         \n    horizontal_flip=True,   \n    brightness_range=[0.8,1.2] \n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    '/kaggle/working/dataset_split/train',\n    target_size=(224,224),\n    batch_size=32,\n    class_mode='categorical'\n)\n\nx_batch, y_batch = next(train_generator)\n\nplt.figure(figsize=(12, 12))\nfor i in range(9):\n    plt.subplot(3, 3, i+1)\n    plt.imshow(x_batch[i])\n    plt.axis(\"off\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:03:18.356726Z","iopub.execute_input":"2025-09-26T06:03:18.356986Z","iopub.status.idle":"2025-09-26T06:03:19.621205Z","shell.execute_reply.started":"2025-09-26T06:03:18.356968Z","shell.execute_reply":"2025-09-26T06:03:19.620183Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Validation ve Test Veri Generator'larının Hazırlanması\n\n✿ Bu hücrede, **validation** ve **test** setleri için `ImageDataGenerator` tanımlanıyor.  \n\n* Sadece **rescale=1./255** uygulanıyor (normalize işlemi).  \n* **Augmentation uygulamıyorum**, çünkü modelin doğrulama ve test performansı gerçekçi değerlendirilmeli.  \n* `flow_from_directory` ile `val` ve `test` klasörlerinden veriler yükleniyor.  \n* `shuffle=False` kullanılarak veri sırası korunuyor.  \n\n✿ Kısaca model eğitiminden bağımsız olarak doğrulama ve test aşamalarında kullanılacak temiz veri akışlarını hazırlamış oluyorum.","metadata":{}},{"cell_type":"code","source":"# Validation için sadece rescale\nval_datagen = ImageDataGenerator(rescale=1./255)\nval_generator = val_datagen.flow_from_directory(\n    '/kaggle/working/dataset_split/val',\n    target_size=(224,224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# Test için sadece rescale\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    '/kaggle/working/dataset_split/test',\n    target_size=(224,224),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:03:25.395821Z","iopub.execute_input":"2025-09-26T06:03:25.396095Z","iopub.status.idle":"2025-09-26T06:03:25.523248Z","shell.execute_reply.started":"2025-09-26T06:03:25.396073Z","shell.execute_reply":"2025-09-26T06:03:25.522545Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Basit CNN Modeli Kurulumu ve Derleme\n\n✿ Bu hücrede de Keras kullanrak sıfırdan bir **Convolutional Neural Network (CNN)** modeli oluşturuyorum.\n\n* **Girdi**: (224x224x3) boyutunda renkli görseller  \n* **Katmanlar**:  \n  -> 3 adet Conv2D + MaxPooling blokları  \n  -> Flatten -> Dense katmanı bağlantısı  \n  -> 256 nöronlu Dense + Dropout(0.5)  \n  ->`softmax` çıkış katmanı (23 sınıf için)  \n\n* **Derleme (compile)**:  \n  -> Optimizer: **Adam** (learning_rate=0.0001)  \n  -> Loss: **categorical_crossentropy**  \n  ->Metric: **accuracy**  \n\n\n✿ Son adımda `model.summary()` çıktısı, her katmanın ismini, çıktı boyutunu ve öğrenilebilir parametre sayısını tablo halinde gösteriyor.   ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers, models, optimizers\n\nnum_classes = 23 \n\nmodel = models.Sequential([\n    # 1. Convolution + Pooling\n    layers.Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n    layers.MaxPooling2D((2,2)),\n    \n    # 2. Convolution + Pooling\n    layers.Conv2D(64, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    \n    # 3. Convolution + Pooling\n    layers.Conv2D(128, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    \n    layers.Flatten(),         \n    \n    layers.Dense(256, activation='relu'), \n    layers.Dropout(0.5),                  \n    \n    layers.Dense(num_classes, activation='softmax') \n])\n\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:03:28.843654Z","iopub.execute_input":"2025-09-26T06:03:28.844330Z","iopub.status.idle":"2025-09-26T06:03:28.914341Z","shell.execute_reply.started":"2025-09-26T06:03:28.844307Z","shell.execute_reply":"2025-09-26T06:03:28.913365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelin Eğitilmesi ve Eğitim Sürecinin Görselleştirilmesi\n\n✿ Bu hücrede CNN modelinin, eğitim ve doğrulama setleri üzerinden **25 epoch** boyunca eğitilmesini sağladım.  \n`history` objesi, eğitim sırasında kaydedilen accuracy ve loss değerlerini saklıyor.  \n\n- **Sol grafik**: Eğitim ve doğrulama accuracy (başarı oranı)  \n- **Sağ grafik**: Eğitim ve doğrulama loss (kayıp)  \n\nBu görseller sayesinde:  \n- Modelin **öğrenme eğrisi** takip edilebiliyor.  \n- **Overfitting/underfitting** belirtileri gözlemlenebiliyor (örn. doğrulama kaybının artması).","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nepochs = 25\nbatch_size = 64 \n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,\n    validation_data=val_generator,\n    validation_steps=val_generator.samples // batch_size,\n    epochs=epochs\n)\n\nplt.figure(figsize=(12,5))\n\n# Accuracy\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Val Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:03:32.803810Z","iopub.execute_input":"2025-09-26T06:03:32.804085Z","iopub.status.idle":"2025-09-26T06:26:13.724158Z","shell.execute_reply.started":"2025-09-26T06:03:32.804066Z","shell.execute_reply":"2025-09-26T06:26:13.723202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre-trained VGG16 ile Transfer Learning Modeli\n\nHenüz yeterli veriye ulaşamadığımı düşündüğüm için :') **pre trained VGG16** kullanarak transfer learning uyguluyorum. Böylece daha az veriyle yüksek performans elde edilebilir.\n\n1. **Base Model**  \n   - `VGG16(weights='imagenet', include_top=False)` ile ImageNet üzerinde eğitilmiş ağırlıklar yükleniyor.  \n   - `include_top=False` Orijinal sınıflandırma katmanları kaldırılıyor, sadece özellik çıkarıcı katmanlar alınıyor.  \n   - `input_shape=(224,224,3)` Modelin giriş boyutu ayarlanıyor.  \n\n2. **Base model dondurma**  \n   - `base_model.trainable = False` ile önceden öğrenilmiş katmanlar eğitim sırasında güncellenmeyecek, sadece üst katmanlar eğitilecek.  \n\n3. **Yeni üst katmanlar ekleme**  \n   - Flatten -> Dense(256, relu) -> Dropout(0.5) -> Dense(23, softmax)  \n   - Bu katmanlar datasetimizdeki sınıfları öğrenmek için eklendi.  \n\n4. **Compile**  \n   - Optimizer: Adam (lr=0.0001)  \n   - Loss: Categorical Crossentropy  \n   - Metric: Accuracy  \n\n* `model.summary()` ile modelin mimarisi ve toplam parametre sayısı görüntüleniyor.  \n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras import layers, models, optimizers\n\n# dataset için\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# görselleştirme için\nimport matplotlib.pyplot as plt\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:30:04.332743Z","iopub.execute_input":"2025-09-26T06:30:04.333285Z","iopub.status.idle":"2025-09-26T06:30:04.348510Z","shell.execute_reply.started":"2025-09-26T06:30:04.333263Z","shell.execute_reply":"2025-09-26T06:30:04.347774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n\nbase_model.trainable = False\n\n# Yeni üst katmanlar\nmodel = models.Sequential([\n    base_model,\n    layers.Flatten(),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(23, activation='softmax')\n])\n\nmodel.compile(\n    optimizer=optimizers.Adam(learning_rate=0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:30:07.539975Z","iopub.execute_input":"2025-09-26T06:30:07.540763Z","iopub.status.idle":"2025-09-26T06:30:08.211845Z","shell.execute_reply.started":"2025-09-26T06:30:07.540728Z","shell.execute_reply":"2025-09-26T06:30:08.211138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Modelinin Eğitilmesi\n\n✿ Bu hücrede, VGG16 tabanlı transfer learning modeli eğitim ve doğrulama setleri üzerinde **25 epoch** boyunca eğitiliyor.  \n\n- `train_generator` -> Eğitim verilerini besler (augmentation + normalize)  \n- `val_generator` -> Doğrulama verilerini besler (sadece normalize)  \n- `steps_per_epoch` ve `validation_steps` -> Her epoch için kaç batch işleneceğini belirler  \n\n✿ Eğitim sırasında `history` objesi, her epoch sonrası **loss** ve **accuracy** değerlerini saklar. Bu değerleri eğitim eğrilerini görselleştirmek için kullanacağım.","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // 64,\n    validation_data=val_generator,\n    validation_steps=val_generator.samples // 64,\n    epochs=25\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:30:15.774108Z","iopub.execute_input":"2025-09-26T06:30:15.774404Z","iopub.status.idle":"2025-09-26T06:57:48.039129Z","shell.execute_reply.started":"2025-09-26T06:30:15.774383Z","shell.execute_reply":"2025-09-26T06:57:48.038523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transfer Learning Modeli Eğitim Sonuçlarının Görselleştirilmesi\n\n✿ `Sol grafikte`, eğitim ve **accuracy** değerleri, `sağ grafikte` eğitim ve **loss** değerleri epoch bazında gösteriliyor.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Accuracy grafiği\nplt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Loss grafiği\nplt.subplot(1,2,2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:59:05.266209Z","iopub.execute_input":"2025-09-26T06:59:05.266805Z","iopub.status.idle":"2025-09-26T06:59:05.613258Z","shell.execute_reply.started":"2025-09-26T06:59:05.266775Z","shell.execute_reply":"2025-09-26T06:59:05.612470Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"≽^•⩊•^≼ Bu görüntü hoşuma gittiği için modeli kendi bilgisayarıma yüklüyorum. ≽^•⩊•^≼","metadata":{}},{"cell_type":"code","source":"model.save('/kaggle/working/sea_animals_cnn_vgg16.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:59:20.794002Z","iopub.execute_input":"2025-09-26T06:59:20.794608Z","iopub.status.idle":"2025-09-26T06:59:21.056497Z","shell.execute_reply.started":"2025-09-26T06:59:20.794552Z","shell.execute_reply":"2025-09-26T06:59:21.055722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nmodel_path = \"/kaggle/working/sea_animals_cnn_vgg16.h5\"\nshutil.make_archive(\"/kaggle/working/sea_animals_cnn_vgg16.h5\", 'zip', root_dir=\"/kaggle/working\", base_dir=\"sea_animals_cnn_vgg16.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T06:59:24.756313Z","iopub.execute_input":"2025-09-26T06:59:24.756992Z","iopub.status.idle":"2025-09-26T06:59:32.385911Z","shell.execute_reply.started":"2025-09-26T06:59:24.756967Z","shell.execute_reply":"2025-09-26T06:59:32.385105Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test Seti Üzerinde Model Değerlendirmesi\n\n✿ Bu hücrede, eğitilmiş model **test seti** üzerinde değerlendirilerek performansı detaylı olarak inceleyebiliriz.\n\n1. **Tahminler (Predictions)**  \n   - `model.predict(test_generator)` ile test setindeki tüm görseller için sınıf olasılıkları elde ediliyor.  \n   - `np.argmax` ile en yüksek olasılığa sahip sınıf seçiliyor.  \n\n2. **Confusion Matrix (Karışıklık Matrisi)**  \n   - `confusion_matrix(y_true, y_pred)` ile gerçek ve tahmin edilen sınıflar karşılaştırılıyor.  \n   - `seaborn` ile görselleştiriliyor.  \n   - Matristeki yüksek değerler doğru sınıflandırmaları, yanlış sınıflandırmalar ise düşük değerlerle gösteriliyor.  \n\n3. **Classification Report**  \n   - `precision`, `recall`, `f1-score` ve `support` değerleri her sınıf için hesaplanıyor.  \n   - Modelin hangi sınıflarda güçlü veya zayıf olduğu anlaşılabiliyor. ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport seaborn as sns\n\n# Test generatordan tüm veriyi tahmin et\ny_pred_probs = model.predict(test_generator)\ny_pred = np.argmax(y_pred_probs, axis=1)\ny_true = test_generator.classes\n\n# Confusion matrix\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(15,12))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Classification report\nprint(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:00:58.238168Z","iopub.execute_input":"2025-09-26T07:00:58.239036Z","iopub.status.idle":"2025-09-26T07:01:25.549496Z","shell.execute_reply.started":"2025-09-26T07:00:58.239013Z","shell.execute_reply":"2025-09-26T07:01:25.548932Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grad-CAM için Gerekli Kütüphanelerin İçe Aktarılması","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:01:34.609177Z","iopub.execute_input":"2025-09-26T07:01:34.609732Z","iopub.status.idle":"2025-09-26T07:01:34.613854Z","shell.execute_reply.started":"2025-09-26T07:01:34.609709Z","shell.execute_reply":"2025-09-26T07:01:34.612909Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Eğitilmiş Modelin Yüklenmesi ve Katmanlarının İncelenmesi\n\n✿ Daha önce eğittiğim CNN modeli (`sea_animals_cnn_vgg16.h5`) **yükleniyor**:\n\n- `tf.keras.models.load_model(model_path)` ile model dosyası belleğe alınıyor.  \n- `model.summary()` ile modelin tüm katmanları, çıktı boyutları ve parametre sayıları görüntüleniyor.  \n- Katman isimleri ve yapısı, **Grad-CAM uygularken hangi convolutional katmanı hedefleyeceğimizi belirlemek** için önemli.  ","metadata":{}},{"cell_type":"code","source":"model_path = \"/kaggle/working/sea_animals_cnn_vgg16.h5\"\nmodel = tf.keras.models.load_model(model_path)\nmodel.summary()  # Hangi layer isimlerini kullanabileceğini görmek için","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:01:38.923560Z","iopub.execute_input":"2025-09-26T07:01:38.924307Z","iopub.status.idle":"2025-09-26T07:01:39.186405Z","shell.execute_reply.started":"2025-09-26T07:01:38.924283Z","shell.execute_reply":"2025-09-26T07:01:39.185723Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grad-CAM için Base Model ve Son Convolutional Katmanın Seçilmesi\n\n✿ Bu hücrede Grad-CAM hesaplaması için gerekli model kısmı ve hedef katman tanımlıyorum.\n\n1. **Base Model**  \n   - `base_model = model.get_layer('vgg16')` -> Transfer learning kısmı olan VGG16 modeli alınıyor.  \n   - `summary()` çıktısına göre katman ismi doğrulanıyor.  \n\n2. **Son Convolutional Katman**  \n   - `last_conv_layer_name = \"block5_conv3\"` -> Grad-CAM için son conv katman seçilir.  \n   - Bu katman, modelin sınıflandırma kararına en çok katkıda bulunan feature map’leri içeriyor. ","metadata":{}},{"cell_type":"code","source":"# Base model (VGG16 kısmı)\nbase_model = model.get_layer('vgg16')  \nlast_conv_layer_name = \"block5_conv3\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:01:43.504175Z","iopub.execute_input":"2025-09-26T07:01:43.504467Z","iopub.status.idle":"2025-09-26T07:01:43.508396Z","shell.execute_reply.started":"2025-09-26T07:01:43.504444Z","shell.execute_reply":"2025-09-26T07:01:43.507632Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Base Model’in Tensorlarının Hazırlanması için Dummy Çağrı\n\n✿ Burada Grad-CAM hesaplaması için **modelin input ve output tensorlarını** hazırlıyorum.\n\n- `dummy_input` ile (1, 224, 224, 3) boyutunda boş bir örnek tensor oluşturuluyor.  \n- `base_model(dummy_input)` çağrısı ile modelin katmanları çalıştırılıyor ve tensor yapıları aktive ediliyor.  ","metadata":{}},{"cell_type":"code","source":"dummy_input = np.zeros((1, 224, 224, 3), dtype=np.float32)\n_ = base_model(dummy_input)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:01:49.267839Z","iopub.execute_input":"2025-09-26T07:01:49.268109Z","iopub.status.idle":"2025-09-26T07:01:50.266259Z","shell.execute_reply.started":"2025-09-26T07:01:49.268089Z","shell.execute_reply":"2025-09-26T07:01:50.265695Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grad-CAM Heatmap Hesaplama Fonksiyonu\n\n✿ Modelin görüntü üzerinde **hangi bölgelere dikkat ettiğini** görselleştirmek için bir fonksiyon tanımlıyorum.\n\n1. **Hedef Katman Çıkışı**  \n     \n2. **Gradyan Hesaplama**  \n \n3. **Heatmap Oluşturma**  \n     ","metadata":{}},{"cell_type":"code","source":"def get_gradcam_heatmap(img_array, base_model, last_conv_layer_name='block5_conv3'):\n    last_conv_layer = base_model.get_layer(last_conv_layer_name)\n    grad_model = tf.keras.models.Model(\n        inputs=base_model.input,\n        outputs=last_conv_layer.output\n    )\n\n    with tf.GradientTape() as tape:\n        conv_outputs = grad_model(img_array)\n        # Dummy prediction için feature maplerin toplamını kullanıyoruz\n        class_channel = tf.reduce_mean(conv_outputs, axis=-1)\n\n    grads = tape.gradient(class_channel, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:01.732967Z","iopub.execute_input":"2025-09-26T07:02:01.733238Z","iopub.status.idle":"2025-09-26T07:02:01.738850Z","shell.execute_reply.started":"2025-09-26T07:02:01.733218Z","shell.execute_reply":"2025-09-26T07:02:01.738213Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Grad-CAM Heatmap’in Görselleştirilmesi ve Kaydedilmesi\n\n✿ Bu hücrede, hesaplanan Grad-CAM heatmap’in orijinal görselle birleştirilerek görselleştirilmesi sağlıyorum.\n\n1. **Görselin Yüklenmesi**  \n   - `cv2.imread` ile görüntü okunur ve RGB formatına çevriliyor.  \n\n2. **Heatmap İşleme**  \n   - Heatmap, orijinal görsel boyutuna yeniden boyutlandırılır.  \n   - 0–255 aralığına normalize edilip renkli bir colormap (`COLORMAP_JET`) uygulanır.  \n\n3. **Görsellerin Birleştirilmesi**  \n   - `superimposed_img = heatmap * alpha + img` ile heatmap, orijinal görsele saydamlık (`alpha`) ile bindirilir.  \n\n4. **Görselleştirme**  \n   - `matplotlib` ile görsel çizdirilir ve eksenler gizlenir.  ","metadata":{}},{"cell_type":"code","source":"def save_and_display_gradcam(img_path, heatmap, alpha=0.4):\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n    superimposed_img = heatmap * alpha + img\n    plt.figure(figsize=(6,6))\n    plt.imshow(np.uint8(superimposed_img))\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:06.703983Z","iopub.execute_input":"2025-09-26T07:02:06.704704Z","iopub.status.idle":"2025-09-26T07:02:06.709374Z","shell.execute_reply.started":"2025-09-26T07:02:06.704682Z","shell.execute_reply":"2025-09-26T07:02:06.708554Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Grad-CAM için kullanılacak test görselini hazırlıyorum.\n\n1. **Görselin Yüklenmesi**  \n   - `load_img(test_img_path, target_size=(224,224))` ile görsel belirtilen boyuta yeniden boyutlandırılarak yüklenir.  \n\n2. **Array’e Dönüştürme**  \n   - `img_to_array(img)` ile NumPy array formatına çevrilir.  \n   - `np.expand_dims(img_array, axis=0)` ile batch boyutu eklenir, modelin beklediği input shape sağlanır.  \n\n3. **Normalize Etme**  \n   - Piksel değerleri 0–1 aralığına getirilir ( veri ölçeklemesi uygunluğu için)   ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\n\ntest_img_path = \"/kaggle/working/merged_dataset/Corals/coral1.jpg\"\nimg = load_img(test_img_path, target_size=(224,224))\nimg_array = img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0) / 255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:10.629026Z","iopub.execute_input":"2025-09-26T07:02:10.629567Z","iopub.status.idle":"2025-09-26T07:02:10.660985Z","shell.execute_reply.started":"2025-09-26T07:02:10.629544Z","shell.execute_reply":"2025-09-26T07:02:10.660401Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Hazırladığım test görseli için Grad-CAM heatmap hesaplanıyor ve orijinal görsel üzerine bindirilerek gösteriliyor.","metadata":{}},{"cell_type":"code","source":"heatmap = get_gradcam_heatmap(img_array, base_model, last_conv_layer_name)\nsave_and_display_gradcam(test_img_path, heatmap)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:14.792636Z","iopub.execute_input":"2025-09-26T07:02:14.793450Z","iopub.status.idle":"2025-09-26T07:02:17.087936Z","shell.execute_reply.started":"2025-09-26T07:02:14.793427Z","shell.execute_reply":"2025-09-26T07:02:17.087117Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Keras Tuner Kütüphanesinin Kurulması ve İçe Aktarılması","metadata":{}},{"cell_type":"code","source":"!pip install keras-tuner -q\nimport keras_tuner as kt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:22.510733Z","iopub.execute_input":"2025-09-26T07:02:22.510991Z","iopub.status.idle":"2025-09-26T07:02:30.405647Z","shell.execute_reply.started":"2025-09-26T07:02:22.510973Z","shell.execute_reply":"2025-09-26T07:02:30.404656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Keras Tuner ve Veri Hazırlığı için Kütüphanelerin İçe Aktarılması ve Parametrelerin Tanımlanması\n\nBu hücrede:\n\n1. **Kütüphaneler yükleniyor**  \n   - `tensorflow` ve `keras.preprocessing.image` → Model ve veri işlemleri için  \n   - `keras_tuner` → Hiperparametre optimizasyonu için  \n   - `numpy` ve `matplotlib.pyplot` → Veri işleme ve görselleştirme için  \n\n2. **Dataset yolları belirleniyor**  \n   - `train_dir` → Eğitim seti klasörü  \n   - `val_dir` → Doğrulama seti klasörü  \n\n3. **Hiperparametreler ve batch ayarları**  \n   - `IMG_SIZE = (224, 224)` → Görsellerin yeniden boyutlandırılacağı boyut  \n   - `BATCH_SIZE = 32` → Her batch’te işlenecek görsel sayısı (ε(´｡•᎑•`)っ☆ 64 seçmedim çünkü 32 de hafıza daha az kullanılıyor ve gradyan güncellemeleri daha sık)","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport keras_tuner as kt\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntrain_dir = \"/kaggle/working/dataset_split/train\"\nval_dir = \"/kaggle/working/dataset_split/val\"\n\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:41.798215Z","iopub.execute_input":"2025-09-26T07:02:41.798538Z","iopub.status.idle":"2025-09-26T07:02:41.803037Z","shell.execute_reply.started":"2025-09-26T07:02:41.798510Z","shell.execute_reply":"2025-09-26T07:02:41.802378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Eğitim ve Doğrulama Verisi için Data Augmentation ve Normalizasyon\n\n✿ Model eğitimini başlatmadan önce veriyi uygun formatta ve çeşitlilikte hazırlamak için, Keras Tuner ile kullanılacak eğitim ve doğrulama veri generatorlarını hazırlıyorum.\n\n1. **Eğitim verisi için augmentation (`train_datagen`)**  \n   - `rescale=1./255` -> Piksel değerlerini 0–1 aralığına getirir.  \n   - `rotation_range`, `width_shift_range`, `height_shift_range`, `shear_range`, `zoom_range`, `horizontal_flip`-> Veri çeşitliliğini artırarak modelin daha genelleyici öğrenmesini sağlar.  \n   - `fill_mode='nearest'` -> Görsel taşma/padding durumunda yeni piksellerin doldurma yöntemi.\n\n2. **Doğrulama verisi için sadece normalizasyon (`val_datagen`)**  \n   - Validation verisi augmentation uygulanmadan sadece normalize ediliyor, böylece gerçek doğrulama performansı ölçülür.\n\n3. **Generator’lar (`flow_from_directory`)**  \n   - `train_generator` ve `val_generator` -> Eğitim ve doğrulama verilerini batch batch modele besler.  \n   - `target_size=IMG_SIZE` -> Görseller 224x224 boyutuna yeniden boyutlandırılır.  \n   - `batch_size=BATCH_SIZE` -> Her batch’te işlenecek örnek sayısı  \n   - `class_mode='categorical'` -> Çok sınıflı sınıflandırma için.\n\n","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Generatorlar\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:48.787372Z","iopub.execute_input":"2025-09-26T07:02:48.787684Z","iopub.status.idle":"2025-09-26T07:02:49.061792Z","shell.execute_reply.started":"2025-09-26T07:02:48.787660Z","shell.execute_reply":"2025-09-26T07:02:49.060741Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Keras Tuner için Model Oluşturma Fonksiyonu (`build_model`)\n\n✿ Bu hücrede, **hiperparametre optimizasyonu için model oluşturma fonksiyonu** tanımlıyorum.\n\n1. **Base Model**  \n   - `VGG16` önceden eğitilmiş modeli yüklenir  \n   - `base_model.trainable = False` -> Transfer learning uygulanır, base katmanlar eğitilmez.\n\n2. **Yeni Üst Katmanlar**    \n   - Bu katmanlar datasetimizdeki sınıfları öğrenmek için eklenir.\n\n3. **Hiperparametreler (`hp`)**  \n   - `learning_rate` → [0.001, 0.0001, 0.01] seçeneklerinden seçim yapılabilir.  \n   - `optimizer_choice` → ['adam','rmsprop','sgd'] seçeneklerinden biri kullanılır.  \n   - Seçilen optimizer ve learning rate ile model compile edilir.  ","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    base_model = tf.keras.applications.VGG16(\n        input_shape=(224,224,3),\n        include_top=False,\n        weights='imagenet'\n    )\n    base_model.trainable = False  # Transfer learning\n\n    model = tf.keras.Sequential([\n        base_model,\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n    ])\n\n    # Hiperparametreler\n    learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4, 1e-2])\n    optimizer_choice = hp.Choice('optimizer', values=['adam','rmsprop','sgd'])\n\n    if optimizer_choice == 'adam':\n        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n    elif optimizer_choice == 'rmsprop':\n        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n    else:\n        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:02:54.490065Z","iopub.execute_input":"2025-09-26T07:02:54.490309Z","iopub.status.idle":"2025-09-26T07:02:54.496694Z","shell.execute_reply.started":"2025-09-26T07:02:54.490293Z","shell.execute_reply":"2025-09-26T07:02:54.496088Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Keras Tuner ile Random Search Tuner Oluşturma\n\n✿ `RandomSearch` kullanarak **hiperparametre araması için tuner** oluşturuyorum. Bu adımı, farklı learning rate ve optimizer kombinasyonlarını otomatik olarak denemek ve en iyi performansı veren modeli bulmak için yapıyorum.\n\n- `build_model` -> Hangi modelin ve hiperparametre aralığının kullanılacağını belirler.  \n- `objective='val_accuracy'` -> Tuner, doğrulama doğruluk (validation accuracy) değerini maksimize etmeye çalışır.\n- `max_trials=5` -> Tuner 5 farklı hiperparametre kombinasyonunu dener (deneme sayısı).  \n- `directory='tuner_dir'` ve `project_name='all_classes_tuner'` ->  Arama sonuçları kaydediliyor ve proje organizasyonu sağlanıyor.  ","metadata":{}},{"cell_type":"code","source":"tuner = kt.RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=5,\n    directory='tuner_dir',\n    project_name='all_classes_tuner'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:03:03.762064Z","iopub.execute_input":"2025-09-26T07:03:03.762766Z","iopub.status.idle":"2025-09-26T07:03:04.058112Z","shell.execute_reply.started":"2025-09-26T07:03:03.762741Z","shell.execute_reply":"2025-09-26T07:03:04.057349Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Keras Tuner ile Hiperparametre Aramasının Başlatılması\n\n✿ Bu hücrede, `tuner.search` ile **model hiperparametreleri otomatik olarak deneniyor**\n\n✿ Keras Tuner'in otomatik olarak optimizer ve learning rate gibi parametreleri test edip en iyi performansı veren modeli seçmesini sağlar.","metadata":{}},{"cell_type":"code","source":"tuner.search(\n    train_generator,\n    validation_data=val_generator,\n    epochs=5,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T07:03:08.032454Z","iopub.execute_input":"2025-09-26T07:03:08.033039Z","iopub.status.idle":"2025-09-26T08:11:29.289018Z","shell.execute_reply.started":"2025-09-26T07:03:08.033012Z","shell.execute_reply":"2025-09-26T08:11:29.288415Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ Doğrulama setimde yakaladığım başarı yetersiz olunca :') base modelin son birkaç katmanını açıp (fine-tuning) epoch sayımı artırıyorum.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport keras_tuner as kt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:15:27.425018Z","iopub.execute_input":"2025-09-26T08:15:27.425804Z","iopub.status.idle":"2025-09-26T08:15:27.441257Z","shell.execute_reply.started":"2025-09-26T08:15:27.425770Z","shell.execute_reply":"2025-09-26T08:15:27.440340Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Veri Yükleme (DataLoader)\n\n✿ Bu hücrede **`cleaned_dataset`** kullanarak eğitim ve doğrulama verileri hazırlıyorum.\n\n- **`ImageDataGenerator`** ile veri artırma (augmentation) uyguluyorum. Böylece modelim hem veri çeşitliliği kazanacak hem de overfitting riskini azaltacak.","metadata":{}},{"cell_type":"code","source":"img_size = (224, 224)\nbatch_size = 32\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntrain_generator = train_datagen.flow_from_directory(\n    \"cleaned_dataset\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset=\"training\"\n)\n\nval_generator = train_datagen.flow_from_directory(\n    \"cleaned_dataset\",\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\",\n    subset=\"validation\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:15:32.535826Z","iopub.execute_input":"2025-09-26T08:15:32.536090Z","iopub.status.idle":"2025-09-26T08:15:33.199216Z","shell.execute_reply.started":"2025-09-26T08:15:32.536070Z","shell.execute_reply":"2025-09-26T08:15:33.198637Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# HyperModel (Fine-Tuning Destekli)\n\n✿ Keras Tuner kullanılarak **en iyi hiperparametre kombinasyonunu** bulmak için kullandığım bu hücrede  **VGG16 tabanlı transfer learning modeli** ve **hyperparameter tuning** için model mimarisi tanımlıyorum.\n\n- **Fine-Tuning**\n  - Son 4 katman eğitilebilir (`trainable=True`), diğer katmanlar donduruluyor (`trainable=False`).\n  - Bu sayede model, önceden öğrenilmiş özellikleri korurken yeni veri setimize uyum sağlıyor.","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    base_model = keras.applications.VGG16(\n        include_top=False, \n        input_shape=(224,224,3),\n        weights=\"imagenet\"\n    )\n\n    # Son birkaç katmanı açalım (fine-tuning)\n    for layer in base_model.layers[:-4]:\n        layer.trainable = False\n    for layer in base_model.layers[-4:]:\n        layer.trainable = True\n\n    x = layers.Flatten()(base_model.output)\n    x = layers.Dense(\n        units=hp.Choice(\"dense_units\", [128, 256, 512]),\n        activation=\"relu\"\n    )(x)\n    x = layers.Dropout(hp.Float(\"dropout\", 0.3, 0.6, step=0.1))(x)\n    output = layers.Dense(train_generator.num_classes, activation=\"softmax\")(x)\n\n    model = keras.Model(inputs=base_model.input, outputs=output)\n\n    model.compile(\n        optimizer=hp.Choice(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"]),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:15:37.428988Z","iopub.execute_input":"2025-09-26T08:15:37.429259Z","iopub.status.idle":"2025-09-26T08:15:37.435715Z","shell.execute_reply.started":"2025-09-26T08:15:37.429226Z","shell.execute_reply":"2025-09-26T08:15:37.434705Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"✿ *Keras Tuner** ile hiperparametre optimizasyonu için **Random Search** yöntemi tanımlıyorum.\n\n✿ Bu tuner, **en iyi Dense layer boyutu, dropout oranı ve optimizer** kombinasyonunu belirlemek için kullanılıyor ve tüm sınıflar üzerinden çalışacak şekildedir.\n\n- **Tuner Türü:**\n  - `kt.RandomSearch` → rastgele hiperparametre kombinasyonlarını dener.\n  \n- **Parametreler:**\n  - `build_model` → önceki hücrede tanımlanan HyperModel fonksiyonu.\n  - `objective=\"val_accuracy\"` → doğrulama doğruluğu en iyi olan modeli seçmek için hedef.\n  - `max_trials=5` → toplam deneme sayısı.\n  - `executions_per_trial=1` → her denemenin tek bir kez çalıştırılması.","metadata":{}},{"cell_type":"code","source":"tuner = kt.RandomSearch(\n    build_model,\n    objective=\"val_accuracy\",\n    max_trials=5,\n    executions_per_trial=1,\n    directory=\"project_tuner_all_classes\",\n    project_name=\"class_tuning\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:15:44.590376Z","iopub.execute_input":"2025-09-26T08:15:44.590698Z","iopub.status.idle":"2025-09-26T08:15:44.857901Z","shell.execute_reply.started":"2025-09-26T08:15:44.590674Z","shell.execute_reply":"2025-09-26T08:15:44.857279Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Random Search Tuner** kullanılarak modelin en iyi hiperparametreleri belirleniyor ve eğitim başlatılıyor.\n\n(づ๑•ᴗ•๑)づ ☆ Overfitting riskini azaltmak için EarlyStopping kullanıyorum.\n\n- **EarlyStopping Callback:**\n  - `monitor=\"val_loss\"` → doğrulama kaybı izlenir.\n  - `patience=3` → kayıp 3 epoch boyunca iyileşmezse eğitim durur.\n  - `restore_best_weights=True` → durdurulduğunda en iyi ağırlıklar geri yüklenir.","metadata":{}},{"cell_type":"code","source":"stop_early = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n\ntuner.search(\n    train_generator,\n    validation_data=val_generator,\n    epochs=8,   # daha uzun eğitim\n    callbacks=[stop_early],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T08:15:49.899985Z","iopub.execute_input":"2025-09-26T08:15:49.900276Z","iopub.status.idle":"2025-09-26T10:01:28.751383Z","shell.execute_reply.started":"2025-09-26T08:15:49.900252Z","shell.execute_reply":"2025-09-26T10:01:28.750615Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# En İyi Hiperparametrelerin Alınması","metadata":{}},{"cell_type":"code","source":"best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\nprint(best_hps.values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:21:29.374075Z","iopub.execute_input":"2025-09-26T10:21:29.374368Z","iopub.status.idle":"2025-09-26T10:21:29.378867Z","shell.execute_reply.started":"2025-09-26T10:21:29.374347Z","shell.execute_reply":"2025-09-26T10:21:29.378235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n\nprint(\"En iyi Dense layer boyutu:\", best_hps.get(\"dense_units\"))\nprint(\"En iyi Dropout oranı:\", best_hps.get(\"dropout\"))\nprint(\"En iyi optimizer:\", best_hps.get(\"optimizer\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:21:32.501097Z","iopub.execute_input":"2025-09-26T10:21:32.501782Z","iopub.status.idle":"2025-09-26T10:21:32.506258Z","shell.execute_reply.started":"2025-09-26T10:21:32.501756Z","shell.execute_reply":"2025-09-26T10:21:32.505431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = tuner.hypermodel.build(best_hps)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:21:36.623853Z","iopub.execute_input":"2025-09-26T10:21:36.624458Z","iopub.status.idle":"2025-09-26T10:21:36.887619Z","shell.execute_reply.started":"2025-09-26T10:21:36.624428Z","shell.execute_reply":"2025-09-26T10:21:36.886833Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelin Eğitilmesi\n\n✿ Bu hücrede, belirlenen hiperparametrelerle model **eğitim seti üzerinde eğitiyorum** ve doğrulama seti ile performansını izliyorum.\n\n1. `train_generator` -> Modeli eğitmek için kullanılan eğitim verisi  \n2. `validation_data=val_generator` -> Eğitim sırasında modelin doğrulama performansını ölçmek için kullanılır  \n3. `epochs=25` -> Modelin tüm eğitim verisini 25 kez görmesi sağlanır  \n\n> Bu adım, modelin gerçek veri üzerinde öğrenmesini ve doğrulama seti ile overfitting veya underfitting durumlarının kontrolünü sağlıyor. ☆","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=25\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T10:21:40.104868Z","iopub.execute_input":"2025-09-26T10:21:40.105514Z","iopub.status.idle":"2025-09-26T11:25:56.427067Z","shell.execute_reply.started":"2025-09-26T10:21:40.105492Z","shell.execute_reply":"2025-09-26T11:25:56.426453Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Eğitim ve Doğrulama Doğruluğu Grafiği\n\n- `Mavi çizgi:` Eğitim doğruluğu (train accuracy)\n- `Turuncu çizgi:` Doğrulama doğruluğu (validation accuracy)\n\n✿ Model başlangıçta underfitting gösteriyor ama zamanla doğrulama doğruluğu artıyor.\n✿ Epoch ilerledikçe doğrulama doğruluğu hızla yükseliyor ve eğitim doğruluğunu geçiyor. Bu, modelin veriyi öğrenmeye başladığını gösteriyor.\n✿ Genel olarak overfitting belirtileri fazla yok;\n\n# Eğitim ve Doğrulama Kaybı Grafiği\n\n- `Mavi çizgi:` Eğitim kaybı (train loss)\n- `Turuncu çizgi:` Doğrulama kaybı (val loss)\n\n✿ Başlangıçta kayıp yüksek, ilerledikçe düşüyor.\n✿ Eğitim kaybı doğrulama kaybının hemen altına düşmediği için model tamamen ezberlememiş, yani regularization (Dropout) işe yaramış.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Accuracy grafiği\nplt.figure(figsize=(8,5))\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Eğitim ve Doğrulama Doğruluğu')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Loss grafiği\nplt.figure(figsize=(8,5))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Eğitim ve Doğrulama Kaybı')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T11:36:25.861205Z","iopub.execute_input":"2025-09-26T11:36:25.861508Z","iopub.status.idle":"2025-09-26T11:36:26.241758Z","shell.execute_reply.started":"2025-09-26T11:36:25.861481Z","shell.execute_reply":"2025-09-26T11:36:26.240910Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}